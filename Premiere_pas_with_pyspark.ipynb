{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salka18/Integration-de-donn-es-connect-e/blob/salka18/Premiere_pas_with_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BggKmn2lFPAR"
      },
      "source": [
        "# Importing Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "doUYnF-MFPAV"
      },
      "outputs": [],
      "source": [
        "# !pip install --user pyspark (colab)\n",
        "# install Java JDK 8\n",
        "# install SPARK\n",
        "# install pyspark\n",
        "# eventually consider pyspark\n",
        "# eventuelly consider SPARK_HOME, or SPARK_PATH, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ_f-AiJFPAX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install  pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35WjyDgBGTdA",
        "outputId": "7921d2c2-194e-490b-e59b-b81a46e77e81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 43 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 61.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=f7dfef95b81982eedd51866557e36ac1c22d8fb261fcb4bf62b376ff363afba8\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6VCNLoyeFPAX"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.appName(\"Python Spark\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-dL9zSGFPAY"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IF8LJwSbFPAY"
      },
      "outputs": [],
      "source": [
        "df_ratings = spark.read\\\n",
        "    .option(\"delimiter\", \"\\t\")\\\n",
        "    .option(\"header\", \"true\")\\\n",
        "    .option(\"inferSchema\", \"true\")\\\n",
        "    .csv('u.data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ufBzsxuFPAZ",
        "outputId": "aef56a10-7fc2-488b-cbde-9b8037db86fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print the dataframe schema\n",
        "df_ratings.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WfCCu7nFPAZ",
        "outputId": "1124eacb-f5b2-47c0-c6db-b2624b0f3113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------+---------+\n",
            "|user_id|item_id|rating|timestamp|\n",
            "+-------+-------+------+---------+\n",
            "|    196|    242|     3|881250949|\n",
            "|    186|    302|     3|891717742|\n",
            "|     22|    377|     1|878887116|\n",
            "|    244|     51|     2|880606923|\n",
            "|    166|    346|     1|886397596|\n",
            "+-------+-------+------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# show a sample of the data (the dataframe executes the whole pipeline at this stage)\n",
        "df_ratings.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4VjysIUSFPAa"
      },
      "outputs": [],
      "source": [
        "# set the rdd equivalent of the dataframe\n",
        "rdd_ratings = df_ratings.rdd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psz_9U5TFPAb"
      },
      "source": [
        "# Basic Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Fu46J8FPAb"
      },
      "source": [
        "#### Exercice 1 - Number of movies per user (using RDD then Dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M155mkaFPAb"
      },
      "source": [
        "Calculer pour chaque utilisateur le nombre de films notés, et afficher le résultat pour l'un d'entre eux. Utilisez dans un premier temps les RDD puis les Dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeeAx2YjFPAc",
        "outputId": "52a3f02f-5ae0-423b-f408-89dc76c06f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(196, 39)]\n"
          ]
        }
      ],
      "source": [
        "# classical RDD approach\n",
        "result_1 = rdd_ratings.map(lambda t: (t[0], 1)).reduceByKey(lambda v1, v2: v1 + v2).take(1)\n",
        "print(result_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1pixzgWFPAc",
        "outputId": "904eef4a-401d-4725-a0a4-7cdd7f4609f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|user_id|count|\n",
            "+-------+-----+\n",
            "|    196|   39|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# dataframe approach, filtering on the previous user to compare results\n",
        "df_ratings.groupBy('user_id')\\\n",
        "    .count()\\\n",
        "    .filter(df_ratings['user_id']==result_1[0][0])\\\n",
        "    .show(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U3NeC1oFPAc"
      },
      "source": [
        "#### Exercice 2 - Average rating per user (using RDD then Dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "ompHW-fVa1AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBLBsZG_FPAc"
      },
      "source": [
        "Calculer pour chaque utilisateurs la note moyenne donnée et afficher le résultat pour l'un d'entre eux. Utilisez dans un premier temps les RDD puis les Dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7H0VSTUFPAd",
        "outputId": "7225c15d-d656-4444-d7a8-cf555ea9f1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(196, 3.6153846153846154)]\n"
          ]
        }
      ],
      "source": [
        "# classical RDD approach\n",
        "rdd_map = rdd_ratings.map(lambda t: (t[0], int(t[2])))\n",
        "rdd_agg = rdd_map.aggregateByKey(\n",
        "    (0, 0), \n",
        "    lambda x,y: (x[0] + y,    x[1] + 1), \n",
        "    lambda a,b: (x[0] + y[0], x[1] + y[1])\n",
        ")\n",
        "\n",
        "rdd_result = rdd_agg.mapValues(lambda v: float(v[0])/v[1])\n",
        "\n",
        "result_1 = rdd_result.take(1)\n",
        "print(result_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GNSIzF3FPAd",
        "outputId": "70d53943-763f-458e-d8fd-b1b820c3141a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------+\n",
            "|user_id|           moyenne|maximum|\n",
            "+-------+------------------+-------+\n",
            "|    196|3.6153846153846154|      5|\n",
            "+-------+------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# dataframe approach\n",
        "from pyspark.sql.functions import avg, max\n",
        "\n",
        "df_ratings.groupBy('user_id')\\\n",
        "    .agg(avg('rating').alias('moyenne'), max('rating').alias('maximum'))\\\n",
        "    .filter(df_ratings['user_id']==result_1[0][0])\\\n",
        "    .show(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYAD5FUpayae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrE8oAyPFPAd"
      },
      "source": [
        "#### Exercice 3 - Top-5 movies with at least 15 votes (Dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ5aAMFsFPAe"
      },
      "source": [
        "Afficher les 5 meilleurs films parmi ceux qui ont reçu au moins 15 votes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAX8-H73FPAe"
      },
      "source": [
        "*Indices:*\n",
        "* Utiliser df_ratings pour calculer la moyenne, filtrer les films qui ont moins de 15 notes et classer les films par ordre décroissant.\n",
        "* Faire un join avec df_movies pour afficher le nom des films sélectionnés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gPJCtXbFFPAe"
      },
      "outputs": [],
      "source": [
        "df_items = spark.read\\\n",
        "    .option(\"delimiter\", \"|\")\\\n",
        "    .option(\"header\", \"true\")\\\n",
        "    .option(\"inferSchema\", \"true\")\\\n",
        "    .csv('u.item')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings.groupBy('user_id')\\\n",
        "  .agg(count('rating').alias('thiokkou'),avg('rating').alias('banaya'))\\\n",
        "  .show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9HaMGm7b0gf",
        "outputId": "7c6aaf74-7b34-4ba6-f4d6-a168bd965272"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------------------+\n",
            "|user_id|thiokkou|            banaya|\n",
            "+-------+--------+------------------+\n",
            "|    148|      65|               4.0|\n",
            "|    463|     133|2.8646616541353382|\n",
            "|    471|      31|3.3870967741935485|\n",
            "|    496|     129|3.0310077519379846|\n",
            "|    833|     267| 3.056179775280899|\n",
            "+-------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sAVpbsTCFPAe"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import avg, count, col\n",
        "\n",
        "df_gb = df_ratings.groupBy('item_id')\\\n",
        "    .agg(avg('rating'), count('item_id').alias('count'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "illRqMcVFPAf"
      },
      "outputs": [],
      "source": [
        "df_gb = df_gb.filter(df_gb['count'] >= 15)  # same as filter('count>15')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ur3WA0R-FPAf"
      },
      "outputs": [],
      "source": [
        "# join with actual movie features\n",
        "df_join = df_gb.join(df_items, df_gb['item_id']==df_items['movie_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r28EqFqAFPAf",
        "outputId": "227a0632-677c-4155-fb89-794e22e77169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+\n",
            "|         movie_title|      avg(rating)|\n",
            "+--------------------+-----------------+\n",
            "|Close Shave, A (1...|4.491071428571429|\n",
            "|Schindler's List ...|4.466442953020135|\n",
            "|Wrong Trousers, T...|4.466101694915254|\n",
            "|   Casablanca (1942)| 4.45679012345679|\n",
            "|Wallace & Gromit:...|4.447761194029851|\n",
            "+--------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_join.select(col(\"movie_title\"), col(\"avg(rating)\"))\\\n",
        "    .sort(\"avg(rating)\", ascending=False)\\\n",
        "    .show(5)  # Java 8 (does not work with Java 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TQrna1zFPAf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}